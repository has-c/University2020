{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ReliefF import ReliefF\n",
    "from sklearn import tree\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runNB(featuresTrain, labelsTrain, featuresTest, labelsTest):    \n",
    "    clf = GaussianNB()\n",
    "    clf.fit(featuresTrain, labelsTrain)\n",
    "    predictions = clf.predict(featuresTest)\n",
    "    acc = accuracy_score(labelsTest,predictions)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\", header=None)\n",
    "\n",
    "labels = df[3120]\n",
    "features = df.drop(3120, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idiot Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34654377880184334\n",
      "0.6534562211981567\n"
     ]
    }
   ],
   "source": [
    "#class balance\n",
    "print((np.sum(labels == 1))/labels.shape[0])\n",
    "print((np.sum(labels == 0))/labels.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3019 2669  309  699  719]\n",
      "[3049  719 2669 3019  309]\n",
      "[3048  699 2669  719  718]\n",
      "[ 309 3019 2669  719  699]\n",
      "[ 719 2669 3019  699  309]\n",
      "[3048  699 2668 3019 3018]\n",
      "[2669  719  309  699 3019]\n",
      "[ 719 3049 2669 3019  699]\n",
      "[ 309 3019  699 2669  719]\n",
      "[3049 3019  719  699 2669]\n"
     ]
    }
   ],
   "source": [
    "labelSplitTrain1 = list()\n",
    "labelSplitTrain0 = list()\n",
    "labelSplitTest1 = list()\n",
    "labelSplitTest0 = list()\n",
    "\n",
    "accPreSimple = list()\n",
    "accPostSimple = list()\n",
    "accPreClass = list()\n",
    "accPostClass = list()\n",
    "\n",
    "for _ in range(0,10):\n",
    "    \n",
    "    labelsTrain, labelsTest, featuresTrain, featuresTest = train_test_split(labels,features,test_size=0.3)\n",
    "    \n",
    "    labelSplitTrain1.append((np.sum(labelsTrain == 1))/labelsTrain.shape[0])\n",
    "    labelSplitTrain0.append((np.sum(labelsTrain == 0))/labelsTrain.shape[0])\n",
    "    labelSplitTest1.append((np.sum(labelsTest == 1))/labelsTest.shape[0])\n",
    "    labelSplitTest0.append((np.sum(labelsTest == 0))/labelsTest.shape[0])\n",
    "    \n",
    "#     accPre, accPost = simpleImputationRelief(labelsTrain,labelsTest,featuresTrain,featuresTest)\n",
    "#     accPreSimple.append(accPre)\n",
    "#     accPostSimple.append(accPost)\n",
    "    \n",
    "    accPre, accPost = classMeanImputationRelif(labelsTrain,labelsTest,featuresTrain,featuresTest)\n",
    "    accPreClass.append(accPre)\n",
    "    accPostClass.append(accPost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out as pdf\n",
    "pd.DataFrame({'Simple Imputation Pre': accPreSimple,\n",
    "             'Simple Imputation Post': accPostSimple, \n",
    "             'Class Imputation Pre': accPreClass,\n",
    "             'Class Imputation Post': accPostClass}).to_excel(\"results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleImputationRelief(labelsTrain,labelsTest,featuresTrain,featuresTest):\n",
    "    #imputation\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imputedTrainFeatureDf = imp_mean.fit_transform(featuresTrain)\n",
    "    imputedTestFeatureDf = imp_mean.transform(featuresTest)\n",
    "    acc1 = runNB(imputedTrainFeatureDf, labelsTrain, imputedTestFeatureDf, labelsTest)\n",
    "    \n",
    "    #relief\n",
    "    featuresToKeep = 100\n",
    "    fs = ReliefF(n_neighbors=100, n_features_to_keep=featuresToKeep)\n",
    "    reducedFeaturesTrain = fs.fit_transform(imputedTrainFeatureDf, labelsTrain.values)\n",
    "    #extract best features\n",
    "    reducedFeaturesTest = fs.transform(imputedTestFeatureDf)\n",
    "    acc2 = runNB(reducedFeaturesTrain, labelsTrain, reducedFeaturesTest, labelsTest)\n",
    "    \n",
    "    return acc1, acc2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classMeanImputationRelif(labelsTrain,labelsTest,featuresTrain,featuresTest):\n",
    "    #class mean imputation\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "    labels = pd.unique(labelsTest)\n",
    "    imputedTrainFeatureDf = pd.DataFrame()\n",
    "    imputedTestFeatureDf = pd.DataFrame()\n",
    "\n",
    "    trainingLabels = list()\n",
    "    testingLabels = list()\n",
    "\n",
    "    for label in labels:\n",
    "        #subset dataframe\n",
    "        trainDf = featuresTrain[labelsTrain == label]\n",
    "        testDf = featuresTest[labelsTest == label]\n",
    "\n",
    "        trainDf = imp_mean.fit_transform(trainDf)\n",
    "        testDf = imp_mean.transform(testDf)\n",
    "\n",
    "        trainingLabels = trainingLabels + ([label] * trainDf.shape[0])\n",
    "        testingLabels = testingLabels + ([label] * testDf.shape[0])\n",
    "\n",
    "        imputedTrainFeatureDf = pd.concat([imputedTrainFeatureDf, pd.DataFrame(trainDf)], ignore_index=True)\n",
    "        imputedTestFeatureDf = pd.concat([imputedTestFeatureDf, pd.DataFrame(testDf)], ignore_index=True)\n",
    "\n",
    "    labelsTrain = np.array(trainingLabels)\n",
    "    labelsTest = np.array(testingLabels)\n",
    "    acc1 = runNB(imputedTrainFeatureDf, labelsTrain, imputedTestFeatureDf, labelsTest)\n",
    "    \n",
    "    #relief\n",
    "    featuresToKeep = 100\n",
    "    fs = ReliefF(n_neighbors=500, n_features_to_keep=featuresToKeep)\n",
    "    reducedFeaturesTrain = fs.fit_transform(imputedTrainFeatureDf.values, labelsTrain)\n",
    "    #extract best features\n",
    "    reducedFeaturesTest = fs.transform(imputedTestFeatureDf.values)\n",
    "    acc2 = runNB(reducedFeaturesTrain, labelsTrain, reducedFeaturesTest, labelsTest)\n",
    "    \n",
    "    #print top 5 features\n",
    "    print(fs.top_features[:5])\n",
    "#     print(fs.feature_scores[:5])\n",
    "    \n",
    "    return acc1, acc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = pd.read_excel(\"results.xlsx\", sheet_name=\"Feature Ranking\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = top_features.groupby(['Top features']).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking.to_excel(\"ranking.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
