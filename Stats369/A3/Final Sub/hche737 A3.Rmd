---
title: "Stats 369 Assignment 3"
author: "Hasnain Cheena"
date: "07/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(rpart)

set.seed(369)
```

```{r Read in Data}
load("spam.rda")

#create feature-label df
word.df = data.frame(wordmatrix)
col.names = make.names(names(word.df))
names(word.df) = col.names
spam.df = cbind(word.df, df['is_spam'])
```

## Task 1
Use rpart to fit and prune (if necessary) a tree predicting spam/non-spam from the common word counts in the wordmatrix matrix. Report the accuracy with a confusion matrix. Plot the fitted tree (without all the labels) and comment on its shape.

```{r Task 1 - Plot Tree and Prune, fig.width=12, fig.height=6}
spam.tree = rpart(factor(is_spam) ~. , data=spam.df)

#plot cp to see if pruning is needed
plotcp(spam.tree)
printcp(spam.tree)
#prune tree
spam.tree.pruned = prune(spam.tree, cp=0.021)

#plot pruned tree
plot(spam.tree.pruned)
```
From plot and output you can see the tree can be pruned back to a simpler model.Thus the tree was pruned to $c_p=0.021$ as this is the simplest model that is within one standard error of the tree with the lowest error. 

Furthermore, looking at a plot of the tree you can see that at every split the tree branches in the same direction. Each branch further partitions the feature space (number of occurrences of each common word) into regions.Then prediction of a message into spam/not spam occurs by selecting the mode of the region.

```{r Task 1 - Confusion Matrix}
#confusion matrix
y_pred_prob = predict(spam.tree.pruned)
max_idx <- apply(y_pred_prob, 1, which.max)
y_pred = colnames(y_pred_prob)[max_idx]
conf_matrix = with(spam.df, table(actual=is_spam, predicted=y_pred))
conf_matrix
```

## Task 2

Compute $y_i$, $n_i$ and $e_i$ per word. 

```{r Task 2 - Compute yi, ei and ni}
#Find Yi and Ni for calculating word occurrences
common_word_occurance = data.frame()
not_spam_entries.df = word.df[spam.df$is_spam == FALSE, ]
spam_entries.df = word.df[spam.df$is_spam == TRUE, ]
common_words_fixed = names(word.df)
for (word in common_words_fixed){
  
  ni = sum(not_spam_entries.df[, word])
  yi = sum(spam_entries.df[, word])
  
  ei = log(yi + 1) - log(ni + 1) #evidence
  
  row = c(word, yi, ni, ei)
  common_word_occurance = rbind(common_word_occurance, row)
  
}
names(common_word_occurance) = c("word", "yi", "ni", "ei")

head(common_word_occurance)
```

Compute $e_i$ per message. 
```{r Task 2 - Compute ei per message}
#compute total evidence
naive_bayes_classification = data.frame()
for (idx in 1:nrow(word.df)){
  message = word.df[idx, ]
  total_ei = as.numeric(message) %*% as.numeric(common_word_occurance$ei)
  naive_bayes_classification = rbind(naive_bayes_classification, data.frame(message_id = idx,
                                                                            total_ei = c(total_ei)))
}

head(naive_bayes_classification)
```

#### Find Threshold
First a coarse sweep was performed to generally find good threshold values. Then a much finer search was performed using the coarse search results to find the actual threshold. 

The constraint "the proportion of spam predicted is the same as the proportion observed" was interpreted using the following approach:

$$ \frac{TP + FP}{number \space of  \space observations} = \frac{actual \space spam}{number \space of \space observations} $$
$$ TP + FP = actual \space spam $$
```{r Task 2 - Coarse Threshold and Prediction}

#proportion of observed spam
actual_spam = sum(spam.df$is_spam == TRUE)


#brief check - choose threshold
threshold_values = seq(round(min(naive_bayes_classification$total_ei),0), round(max(naive_bayes_classification$total_ei),0))
#perform classification - TRUE if spam and FALSE if not spam
threshold.df = data.frame()
for (threshold in threshold_values){
  num_spam_pred = sum(naive_bayes_classification$total_ei < threshold)
  threshold.df = rbind(threshold.df, c(threshold, num_spam_pred))
}
names(threshold.df) = c("threshold", "number of spam predicted")

c("actual spam" = actual_spam)
threshold.df[347:348, ]
```

From the brief search above you can see threshold values of -47 and -48 seem to predict approximately the same amount of actual spam. In the next step we will fine tune the search to find the right threshold value. 

```{r Task 2 - Fine Threshold and Prediction}

#more fine tuned check - choose threshold
threshold_values = seq(-48, -47, 0.001)
#perform classification - TRUE if spam and FALSE if not spam
threshold.df = data.frame()
for (threshold in threshold_values){
  num_spam_pred = sum(naive_bayes_classification$total_ei < threshold)
  threshold.df = rbind(threshold.df, c(threshold, num_spam_pred))
}
names(threshold.df) = c("threshold", "number of spam predicted")

threshold.df[threshold.df$`number of spam predicted` == actual_spam, ]

```
Thus a threshold of -47.625 produces the condition where the proportion of spam predicted is the same as the proportion observed.

In the next step produce a confusion matrix for the Naive Bayes classifier. 

```{r Task 2 - Confusion Matrix}

threshold = -47.625
naive_bayes_classification$is_spam = naive_bayes_classification$total_ei < threshold

#confusion matrix
conf_matrix = table(actual=spam.df$is_spam, predicted=naive_bayes_classification$is_spam)
conf_matrix
```

## Task 3
Read the description at the UCI archive of how the dataset was constructed. Why is spam/non-spam accuracy likely to be higher with this dataset than in real life? What can you say about the generalisability of the classifier to particular populations of text users?

#### Generalisability 
A large subset of the corpus originates from Singapore thus containing Singaporean English. Hence the classifier produced may work well in Singapore but may not generalise well to other regions of the world because the way we speak/write English differs. 

#### Spam/Non-spam accuracy likely to be higher with this dataset than in real-life?
The dataset was published in 2012 which is 8 years ago. The content of spam/non-spam messages has changed quite drastically since then. Therefore, the classifier will show a higher accuracy with the dataset than when used in real-life in 2020. 